"""Data models for the Agentic Genealogical Process Crawler.

Implements the complete data model as specified:
- Person, Event, Relationship, Assertion, EvidenceClaim, SourceRecord
- MergeCluster, AuditLog
- Queue items (FrontierItem, ClueItem, RevisitItem)
"""
from __future__ import annotations

import hashlib
from datetime import UTC, datetime
from enum import Enum
from typing import Annotated, Any
from uuid import UUID, uuid4

from pydantic import BaseModel, Field, computed_field, model_validator


# =============================================================================
# Enums
# =============================================================================


class SourceTier(int, Enum):
    """Source access tier classification."""
    TIER_0 = 0  # No login required (Wikipedia, Find-a-Grave)
    TIER_1 = 1  # Open APIs (Wikidata SPARQL)
    TIER_2 = 2  # Credentialed (user-provided only)


class EvidenceType(str, Enum):
    """Evidence quality classification."""
    PRIMARY = "primary"      # Created at time of event by participant/witness
    SECONDARY = "secondary"  # Derivative, indexed, transcribed
    AUTHORED = "authored"    # Compiled genealogies, user-submitted


class AssertionStatus(str, Enum):
    """Status of an assertion."""
    VERIFIED = "verified"
    UNVERIFIED = "unverified"
    CONFLICTING = "conflicting"
    REJECTED = "rejected"


class RelationshipType(str, Enum):
    """Types of relationships between persons."""
    PARENT_CHILD = "parent_child"
    SPOUSE = "spouse"
    SIBLING = "sibling"
    OTHER_FAMILY = "other_family"
    ASSOCIATE = "associate"


class EventType(str, Enum):
    """Types of life events."""
    BIRTH = "birth"
    DEATH = "death"
    MARRIAGE = "marriage"
    DIVORCE = "divorce"
    BURIAL = "burial"
    CENSUS = "census"
    IMMIGRATION = "immigration"
    MILITARY = "military"
    OCCUPATION = "occupation"
    RESIDENCE = "residence"
    OTHER = "other"


class QueueItemStatus(str, Enum):
    """Status of queue items."""
    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    FAILED = "failed"
    SKIPPED = "skipped"


class HypothesisType(str, Enum):
    """Types of hypotheses generated by LLM."""
    PARENTAL_DISCOVERY = "parental_discovery"
    SPOUSAL_DISCOVERY = "spousal_discovery"
    SIBLING_DISCOVERY = "sibling_discovery"
    NAME_VARIANT = "name_variant"
    DATE_REFINEMENT = "date_refinement"
    PLACE_REFINEMENT = "place_refinement"
    RECORD_SUGGESTION = "record_suggestion"
    RELATIONSHIP_INFERENCE = "relationship_inference"


class AuditActionType(str, Enum):
    """Types of audit log actions."""
    CREATE = "create"
    UPDATE = "update"
    MERGE = "merge"
    SPLIT = "split"
    DELETE = "delete"
    VERIFY = "verify"
    CONFLICT = "conflict"


# =============================================================================
# Source Record
# =============================================================================


class SourceRecord(BaseModel):
    """A record from a genealogical source."""
    id: UUID = Field(default_factory=uuid4)
    url: str
    source_name: str
    source_tier: SourceTier
    accessed_at: datetime = Field(default_factory=lambda: datetime.now(UTC))
    content_hash: str | None = None
    raw_text: str | None = None
    raw_extracted: dict[str, Any] = Field(default_factory=dict)
    metadata: dict[str, Any] = Field(default_factory=dict)

    # Compliance tracking
    robots_respected: bool = True
    cache_hit: bool = False
    rate_limited: bool = False

    def compute_content_hash(self, content: str) -> str:
        """Compute SHA256 hash of content for deduplication."""
        self.content_hash = hashlib.sha256(content.encode()).hexdigest()
        return self.content_hash


# =============================================================================
# Evidence Claim
# =============================================================================


class EvidenceClaim(BaseModel):
    """A claim extracted from a source with full provenance."""
    id: UUID = Field(default_factory=uuid4)
    source_record_id: UUID
    assertion_id: UUID | None = None

    # Citation
    citation_snippet: str  # Exact quote from source
    snippet_context: str | None = None  # Surrounding text for context

    # Extraction metadata
    extraction_method: str  # "deterministic", "llm_verified", "manual"
    extractor_version: str | None = None

    # Reliability scoring
    source_reliability: Annotated[float, Field(ge=0.0, le=1.0)] = 0.5
    evidence_type: EvidenceType = EvidenceType.SECONDARY

    # LLM verification
    llm_rationale: str | None = None
    llm_confidence: Annotated[float, Field(ge=0.0, le=1.0)] | None = None

    created_at: datetime = Field(default_factory=lambda: datetime.now(UTC))


# =============================================================================
# Assertion
# =============================================================================


class Assertion(BaseModel):
    """An assertion about an entity, backed by evidence claims.

    Every assertion MUST link to one or more EvidenceClaims with citations.
    """
    id: UUID = Field(default_factory=uuid4)
    entity_id: UUID  # Person, Event, or Relationship ID
    entity_type: str  # "person", "event", "relationship"

    # The asserted fact
    field_name: str  # e.g., "birth_date", "death_place"
    field_value: Any  # The asserted value
    field_value_normalized: Any | None = None  # Normalized form

    # Confidence and status
    confidence: Annotated[float, Field(ge=0.0, le=1.0)] = 0.5
    status: AssertionStatus = AssertionStatus.UNVERIFIED

    # Evidence links (populated after creation)
    evidence_claim_ids: list[UUID] = Field(default_factory=list)

    # Metadata
    asserted_at: datetime = Field(default_factory=lambda: datetime.now(UTC))
    asserted_by: str = "system"  # Agent name

    @model_validator(mode="after")
    def validate_has_evidence(self) -> "Assertion":
        """Warn if assertion has no evidence (should be populated later)."""
        # Note: We allow empty evidence_claim_ids during construction
        # but the orchestrator should ensure evidence is linked
        return self


# =============================================================================
# Person
# =============================================================================


class Person(BaseModel):
    """A person entity in the knowledge graph."""
    id: UUID = Field(default_factory=uuid4)

    # Names
    canonical_name: str
    given_name: str | None = None
    surname: str | None = None
    name_variants: list[str] = Field(default_factory=list)  # Aliases, nicknames, maiden names

    # Dates (ranges to handle uncertainty)
    birth_date_earliest: datetime | None = None
    birth_date_latest: datetime | None = None
    birth_date_display: str | None = None  # Human-readable

    death_date_earliest: datetime | None = None
    death_date_latest: datetime | None = None
    death_date_display: str | None = None

    # Places
    birth_place: str | None = None
    birth_place_normalized: str | None = None
    death_place: str | None = None
    death_place_normalized: str | None = None

    # Privacy
    is_living: bool = False
    privacy_redacted: bool = False

    # Confidence
    confidence: Annotated[float, Field(ge=0.0, le=1.0)] = 0.5

    # Metadata
    created_at: datetime = Field(default_factory=lambda: datetime.now(UTC))
    updated_at: datetime = Field(default_factory=lambda: datetime.now(UTC))

    # Merge tracking
    merge_cluster_id: UUID | None = None

    @computed_field
    @property
    def full_name(self) -> str:
        """Return the canonical name."""
        return self.canonical_name

    def is_likely_living(self) -> bool:
        """Conservative check for living status."""
        if self.is_living:
            return True
        if self.death_date_earliest:
            return False
        if self.birth_date_latest:
            current_year = datetime.now(UTC).year
            birth_year = self.birth_date_latest.year
            if current_year - birth_year < 100:
                return True
        return False

    def to_jsonld(self) -> dict[str, Any]:
        """Convert to schema.org/Person JSON-LD."""
        result: dict[str, Any] = {
            "@context": "https://schema.org",
            "@type": "Person",
            "@id": f"urn:uuid:{self.id}",
            "name": self.canonical_name,
        }
        if self.given_name:
            result["givenName"] = self.given_name
        if self.surname:
            result["familyName"] = self.surname
        if self.birth_date_display and not self.privacy_redacted:
            result["birthDate"] = self.birth_date_display
        if self.death_date_display:
            result["deathDate"] = self.death_date_display
        if self.birth_place and not self.privacy_redacted:
            result["birthPlace"] = {"@type": "Place", "name": self.birth_place}
        if self.death_place:
            result["deathPlace"] = {"@type": "Place", "name": self.death_place}
        return result


# =============================================================================
# Event
# =============================================================================


class Event(BaseModel):
    """A life event involving one or more persons."""
    id: UUID = Field(default_factory=uuid4)
    event_type: EventType

    # Date (ranges for uncertainty)
    date_earliest: datetime | None = None
    date_latest: datetime | None = None
    date_display: str | None = None

    # Place
    place: str | None = None
    place_normalized: str | None = None

    # Participants
    participants: list[UUID] = Field(default_factory=list)  # Person IDs
    participant_roles: dict[str, str] = Field(default_factory=dict)  # UUID -> role

    # Confidence
    confidence: Annotated[float, Field(ge=0.0, le=1.0)] = 0.5

    # Metadata
    created_at: datetime = Field(default_factory=lambda: datetime.now(UTC))


# =============================================================================
# Relationship
# =============================================================================


class Relationship(BaseModel):
    """A relationship between two persons."""
    id: UUID = Field(default_factory=uuid4)
    person1_id: UUID
    person2_id: UUID
    relationship_type: RelationshipType

    # Directional info (for parent-child)
    person1_role: str | None = None  # e.g., "parent", "child"
    person2_role: str | None = None

    # Date range
    start_date: datetime | None = None
    end_date: datetime | None = None

    # Confidence
    confidence: Annotated[float, Field(ge=0.0, le=1.0)] = 0.5

    # Metadata
    created_at: datetime = Field(default_factory=lambda: datetime.now(UTC))

    @model_validator(mode="after")
    def validate_different_persons(self) -> "Relationship":
        """Ensure relationship is between different persons."""
        if self.person1_id == self.person2_id:
            raise ValueError("Relationship must be between different persons")
        return self


# =============================================================================
# Merge Cluster
# =============================================================================


class MergeCluster(BaseModel):
    """Tracks merged person records for reversibility."""
    id: UUID = Field(default_factory=uuid4)
    canonical_id: UUID  # The surviving person ID

    # Member records
    member_ids: list[UUID] = Field(default_factory=list)

    # Rationale
    merge_rationale: str
    why_not_split: str | None = None  # Why we believe these are the same

    # Scoring
    similarity_score: Annotated[float, Field(ge=0.0, le=1.0)] = 0.0
    feature_scores: dict[str, float] = Field(default_factory=dict)

    # Reversibility
    is_reversible: bool = True
    original_states: dict[str, dict] = Field(default_factory=dict)  # UUID -> state before merge

    # Metadata
    created_at: datetime = Field(default_factory=lambda: datetime.now(UTC))
    created_by: str = "entity_resolver"


# =============================================================================
# Audit Log
# =============================================================================


class AuditLog(BaseModel):
    """Audit trail for all entity modifications."""
    id: UUID = Field(default_factory=uuid4)
    action_type: AuditActionType
    entity_id: UUID
    entity_type: str

    # State tracking
    before_state: dict[str, Any] | None = None
    after_state: dict[str, Any] | None = None

    # Context
    agent_name: str
    rationale: str | None = None

    # Metadata
    timestamp: datetime = Field(default_factory=lambda: datetime.now(UTC))


# =============================================================================
# Queue Items
# =============================================================================


class QueueItem(BaseModel):
    """Base class for queue items."""
    id: UUID = Field(default_factory=uuid4)
    priority: Annotated[float, Field(ge=0.0, le=1.0)] = 0.5
    created_at: datetime = Field(default_factory=lambda: datetime.now(UTC))
    status: QueueItemStatus = QueueItemStatus.PENDING
    retry_count: int = 0
    max_retries: int = 3
    error_message: str | None = None


class FrontierItem(QueueItem):
    """An item in the FrontierQueue - entities/pages to fetch."""
    target_entity_id: UUID | None = None
    target_entity_type: str | None = None  # "person", "event", etc.

    # Query details
    query_string: str
    query_hash: str | None = None  # For novelty checking
    source_tiers: list[SourceTier] = Field(default_factory=lambda: [SourceTier.TIER_0])

    # Context from discovery
    context: dict[str, Any] = Field(default_factory=dict)
    discovered_from: UUID | None = None  # Source that led to this query

    def compute_query_hash(self) -> str:
        """Compute hash for novelty checking."""
        normalized = self.query_string.lower().strip()
        self.query_hash = hashlib.md5(normalized.encode()).hexdigest()
        return self.query_hash


class ClueItem(QueueItem):
    """An item in the ClueQueue - LLM-generated hypotheses."""
    hypothesis_type: HypothesisType
    hypothesis_text: str
    is_fact: bool = False  # MUST be False - hypotheses are not facts

    # Related entities
    related_person_id: UUID | None = None
    related_source_id: UUID | None = None

    # Suggested actions
    suggested_queries: list[str] = Field(default_factory=list)
    suggested_sources: list[str] = Field(default_factory=list)

    # Evidence that triggered this hypothesis
    evidence_hint: str | None = None
    triggering_snippet: str | None = None

    @model_validator(mode="after")
    def validate_not_fact(self) -> "ClueItem":
        """Hypotheses must never be marked as facts."""
        if self.is_fact:
            raise ValueError("ClueItem.is_fact must be False - hypotheses are not facts")
        return self


class RevisitItem(QueueItem):
    """An item in the RevisitQueue - re-query earlier sources."""
    original_source_id: UUID
    original_query: str

    # Improved query
    improved_query: str
    query_improvements: list[str] = Field(default_factory=list)  # What changed

    # Why revisit
    revisit_reason: str
    triggering_clue_id: UUID | None = None
    triggering_discovery: str | None = None

    # Tracking
    last_visited_at: datetime | None = None
    previous_results_hash: str | None = None


# =============================================================================
# Novelty Guard
# =============================================================================


class QueryRecord(BaseModel):
    """Record of a query for novelty checking."""
    query_hash: str
    query_string: str
    source_tier: SourceTier
    executed_at: datetime = Field(default_factory=lambda: datetime.now(UTC))
    result_count: int = 0
    result_hash: str | None = None


class NoveltyGuard(BaseModel):
    """Tracks query history to prevent redundant searches."""
    query_history: dict[str, QueryRecord] = Field(default_factory=dict)  # hash -> record
    similarity_threshold: float = 0.9  # For fuzzy matching

    def is_novel(self, query: str, source_tier: SourceTier) -> bool:
        """Check if a query is novel (not previously executed)."""
        normalized = query.lower().strip()
        query_hash = hashlib.md5(normalized.encode()).hexdigest()
        key = f"{query_hash}:{source_tier.value}"
        return key not in self.query_history

    def record_query(self, query: str, source_tier: SourceTier, result_count: int = 0) -> None:
        """Record a query execution."""
        normalized = query.lower().strip()
        query_hash = hashlib.md5(normalized.encode()).hexdigest()
        key = f"{query_hash}:{source_tier.value}"
        self.query_history[key] = QueryRecord(
            query_hash=query_hash,
            query_string=query,
            source_tier=source_tier,
            result_count=result_count,
        )


# =============================================================================
# Orchestrator State
# =============================================================================


class CrawlerState(BaseModel):
    """Complete state of the genealogical crawler."""
    session_id: UUID = Field(default_factory=uuid4)
    started_at: datetime = Field(default_factory=lambda: datetime.now(UTC))

    # Seed
    seed_person_id: UUID | None = None
    target_generations: int = 4

    # Knowledge graph
    persons: dict[str, Person] = Field(default_factory=dict)  # UUID string -> Person
    events: dict[str, Event] = Field(default_factory=dict)
    relationships: dict[str, Relationship] = Field(default_factory=dict)
    assertions: dict[str, Assertion] = Field(default_factory=dict)
    evidence_claims: dict[str, EvidenceClaim] = Field(default_factory=dict)
    source_records: dict[str, SourceRecord] = Field(default_factory=dict)
    merge_clusters: dict[str, MergeCluster] = Field(default_factory=dict)

    # Queues
    frontier_queue: list[FrontierItem] = Field(default_factory=list)
    clue_queue: list[ClueItem] = Field(default_factory=list)
    revisit_queue: list[RevisitItem] = Field(default_factory=list)

    # Novelty tracking
    novelty_guard: NoveltyGuard = Field(default_factory=NoveltyGuard)

    # Audit
    audit_log: list[AuditLog] = Field(default_factory=list)

    # Budget and limits
    budget_limit: float = 1000.0  # Abstract budget units
    budget_used: float = 0.0
    max_iterations: int = 500
    iteration_count: int = 0

    # Stop condition tracking
    queries_since_last_discovery: int = 0
    recent_discovery_rate: float = 1.0

    # Status
    is_running: bool = False
    is_terminated: bool = False
    termination_reason: str | None = None

    def add_person(self, person: Person) -> None:
        """Add a person to the knowledge graph."""
        self.persons[str(person.id)] = person

    def get_person(self, person_id: UUID | str) -> Person | None:
        """Get a person by ID."""
        return self.persons.get(str(person_id))

    def add_to_frontier(self, item: FrontierItem) -> bool:
        """Add item to frontier if novel."""
        item.compute_query_hash()
        for tier in item.source_tiers:
            if not self.novelty_guard.is_novel(item.query_string, tier):
                return False
        self.frontier_queue.append(item)
        self.frontier_queue.sort(key=lambda x: x.priority, reverse=True)
        return True

    def add_clue(self, clue: ClueItem) -> None:
        """Add a clue to the queue."""
        self.clue_queue.append(clue)
        self.clue_queue.sort(key=lambda x: x.priority, reverse=True)

    def add_revisit(self, item: RevisitItem) -> None:
        """Add a revisit job."""
        self.revisit_queue.append(item)
        self.revisit_queue.sort(key=lambda x: x.priority, reverse=True)

    def pop_frontier(self) -> FrontierItem | None:
        """Pop highest priority frontier item."""
        if not self.frontier_queue:
            return None
        return self.frontier_queue.pop(0)

    def pop_clue(self) -> ClueItem | None:
        """Pop highest priority clue."""
        if not self.clue_queue:
            return None
        return self.clue_queue.pop(0)

    def pop_revisit(self) -> RevisitItem | None:
        """Pop highest priority revisit."""
        if not self.revisit_queue:
            return None
        return self.revisit_queue.pop(0)

    def log_audit(
        self,
        action: AuditActionType,
        entity_id: UUID,
        entity_type: str,
        agent: str,
        before: dict | None = None,
        after: dict | None = None,
        rationale: str | None = None,
    ) -> None:
        """Add an audit log entry."""
        self.audit_log.append(AuditLog(
            action_type=action,
            entity_id=entity_id,
            entity_type=entity_type,
            agent_name=agent,
            before_state=before,
            after_state=after,
            rationale=rationale,
        ))
